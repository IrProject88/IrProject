{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "stemming.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOlWdyBC8xRs",
        "colab_type": "code",
        "outputId": "d8965037-bbb8-478f-eb48-b90e52350d1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import pyarrow.parquet as pq\n",
        "import numpy as np\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oR6BhoK85Kf",
        "colab_type": "code",
        "outputId": "4af15a00-91a6-44be-96b5-734fc4993ed7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCkcCkvq9gFC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stemmer = SnowballStemmer(\"english\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQF90ImLR5Mk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "import pyarrow as pa\n",
        "import pyarrow.parquet as pq\n",
        "import pandas as pd\n",
        "\n",
        "stemmed_data_file = \"stemmed_data.parquet\"\n",
        "stop_words = set(stopwords.words('english'))\n",
        "for i, df in tqdm(enumerate(pd.read_csv(\"drive/My Drive/WashingtonPost.v2/data/tokenized_data.csv\", chunksize=10_000, header=None)), total=60):\n",
        "    df[2] = df[2].map(lambda x: x[1:-1]).map(lambda x: [ stemmer.stem(xi.strip()[1:-1]) for xi in str.split(x, sep=',') if xi.strip()[1:-1] not in stop_words])\n",
        "\n",
        "    table = pa.Table.from_pandas(df)\n",
        "    # for the first chunk of records\n",
        "    if i == 0:\n",
        "        # create a parquet write object giving it an output file\n",
        "        pqwriter = pq.ParquetWriter(stemmed_data_file, table.schema)\n",
        "        pqwriter.write_table(table)\n",
        "    # subsequent chunks can be written to the same file\n",
        "    else:\n",
        "        pqwriter.write_table(table)\n",
        "if pqwriter:\n",
        "    pqwriter.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDhPoY25_I1Y",
        "colab_type": "text"
      },
      "source": [
        "Move file to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZqiMV9BjKX6",
        "colab_type": "code",
        "outputId": "a0725754-754b-497a-ea6a-45ba0803e052",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "!ls -lh"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 881M\n",
            "drwx------ 4 root root 4.0K Dec 19 11:41 drive\n",
            "drwxr-xr-x 1 root root 4.0K Dec 12 16:48 sample_data\n",
            "-rw-r--r-- 1 root root 881M Dec 19 14:19 stemmed_data.parquet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBJ_DgHyjQrk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv 'stemmed_data.parquet' 'drive/My Drive/processed/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyJ028rAiSAc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pathfile = \"/content/drive/My Drive/processed/stemmed_data.parquet\"\n",
        "stemmed_df = pd.read_parquet(pathfile)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}